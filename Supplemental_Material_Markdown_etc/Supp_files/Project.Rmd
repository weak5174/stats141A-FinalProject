---
title: "141A Final Project"
author: "Zheyuan"
date: "12/14/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# --- Data processing and viz ---
library(tidyverse)
library(broom)
library(gridExtra)
library(RColorBrewer)
# --- Stats---
library(corrplot)
library(boot)
library(mclust)
library(PCAtools)
library(MASS)
library(Hmisc)
library(caret)
# --- Spatial Analysis ---> Let's simplify our life haha
library(tmap)
library(leaflet)
#library(sp)
library(sf)
```

### --- Step 0: Packages to mess with --

```{r, eval=FALSE}
    if (!requireNamespace('BiocManager', quietly = TRUE))
        install.packages('BiocManager')

    BiocManager::install('PCAtools')
```


### --- Step 1: Data loading and procressing ---

```{r, "Part A-C: Load and process data I"}
## --- Part a: Upload Metadata for samples ---
#path_data<-file.path(getwd(),"data")
path_data = "C:/Users/yzy/OneDrive/Documents/stats141A-FinalProject/data"
META_DATA<-as_tibble(read.csv(file.path(path_data,"IMPROVE_metadata.csv")))
## --- Filter samples from Korea and Canada ---
US_META<-META_DATA %>% filter(Country %nin% c("KR","CA"))


## --- Filter stats not in continental US ---
US_META<-META_DATA %>% filter(State %nin% c("HI","AK","VI"))

## -- Use Mississippi River as a dividing point for WEst-East US --
MR_coords<-c(47.239722, -95.2075)
POS_Sampler<-as.numeric(US_META$Longitude <MR_coords[2])
# --- 1 are WEst US, 0 are East
US_META<-add_column(US_META,WE_US = POS_Sampler)

## --- Part b: Load samples data ---
DATA<-as_tibble(read.csv(file.path(path_data,"IMPROVE_2015_data_w_UNC_v2.csv")))

## --- Part c: Select samples from SW given site identifiers from SW_META table ("Code")
US_DATA_all<-as_tibble(DATA %>% filter(SiteCode %in% US_META$Code))
```

```{r,"Part D: Check for gross absorbance violations"}
# Let's identify any samples that (grossly) violate PM2.5 mass balances
# PM2.5 (=Y) cannot be negative!
# Since there's some probability that PM2.5 is negative due to errors at low concentration, we may use PM2.5 uncertainties to remove samples that fall outside -3*PM2.5_UNC.
# In this way, we don't risk censoring the data but do remove likely erroneous data.
US_DATA_all<-US_DATA_all %>% dplyr::filter(PM2.5 > -3*PM2.5_UNC)
```

```{r, "Screen proxies, constructs, PM, and useless things"}
exclude<-c("PM10","POC","ammNO3","ammSO4","SOIL","SeaSalt","OC1","OC2","OC3","OC4","EC1","EC2","EC3","fAbs_MDL","fAbs")
US_DATA_LRG<- US_DATA_all %>% dplyr::select(!contains(exclude) & !matches("_UNC") | matches("PM2.5_UNC"))
any(is.na(US_DATA_LRG))
US_DATA_LRG<-US_DATA_LRG[which(complete.cases(US_DATA_LRG)),]
any(is.na(US_DATA_LRG))
```

```{r, "Part F: Partition data into training and testing sets"}
## --- Instead of random partitioning, I will partition by first sorting samples by SiteCode and DATE (already done) and place every other sample in the test set.
# --- This data has seasonality. Sorting by date therefore ensures seasonality is equivalent between datasets
n<-nrow(US_DATA_LRG)
ind_test<-seq(1,n,2)
US_DATA_LRG_test<-US_DATA_LRG[ind_test,]
US_DATA_LRG<-US_DATA_LRG[-ind_test,]
```

#Rgression Analysis
```{r}
#First order model
fit = lm(PM2.5 ~ EC + OC + OP + AL + AS + BR + CA + CL + CR + CU + FE + PB + MG + MN + NI + N2 + P + K + RB + SE + SI + NA. + SR + S + TI + V + ZN + ZR + NO3 + SO4, data = US_DATA_LRG)
summary(fit)
#Assumption check
plot(fit)
#Box Cox Procedure
min(US_DATA_LRG$PM2.5)
fit.b = lm(PM2.5 + 0.26 ~ EC + OC + OP + AL + AS + BR + CA + CL + CR + CU + FE + PB + MG + MN + NI + N2 + P + K + RB + SE + SI + NA. + SR + S + TI + V + ZN + ZR + NO3 + SO4, data = US_DATA_LRG)
boxcox(fit.b)
```
#The QQ plot looks strange, but that just because there are several outliers. The lambda value in Box Cox procedure is very close to 1, which means we do not need to transform PM2.5 to make it more normal. The assumption of homoscedasticity and nonlinearity are valid, too. 
```{r}
#model selection
fit0 = lm(PM2.5 ~ 1, data = US_DATA_LRG)
#forward selection on AIC
mod1 = stepAIC(fit0, scope = list(upper = fit, lower = fit0), direction = "forward", k = 2, trace = FALSE)
#backward elimination on AIC
mod2 = stepAIC(fit, scope = list(upper = fit, lower = fit0), direction = "backward", k = 2, trace = FALSE)
#forward stepwise on AIC
mod3 = stepAIC(fit0, scope = list(upper = fit, lower = fit0), direction = "both", k = 2, trace = FALSE)
#backward stepwise on AIC
mod4 = stepAIC(fit, scope = list(upper = fit, lower = fit0), direction = "forward", k = 2, trace = FALSE)
#forward selection on BIC
mod5 = stepAIC(fit0, scope = list(upper = fit, lower = fit0), direction = "forward", k = log(n), trace = FALSE)
#backward elimination on BIC
mod6 = stepAIC(fit, scope = list(upper = fit, lower = fit0), direction = "backward", k = log(n), trace = FALSE)
#forward stepwise on BIC
mod7 = stepAIC(fit0, scope = list(upper = fit, lower = fit0), direction = "both", k = log(n), trace = FALSE)
#backward stepwise on BIC
mod8 = stepAIC(fit, scope = list(upper = fit, lower = fit0), direction = "forward", k = log(n), trace = FALSE)
summary(mod1)
summary(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
summary(mod6)
summary(mod7)
summary(mod8)
plot(mod1, which = c(1,2))
plot(mod2, which = c(1,2))
plot(mod3, which = c(1,2))
plot(mod4, which = c(1,2))
plot(mod5, which = c(1,2))
plot(mod6, which = c(1,2))
plot(mod7, which = c(1,2))
plot(mod8, which = c(1,2))
#model1
prediction = mod1 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model2
prediction = mod2 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model3
prediction = mod3 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model4
prediction = mod4 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model5
prediction = mod5 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model6
prediction = mod6 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model7
prediction = mod7 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
#model8
prediction = mod8 %>% predict(US_DATA_LRG_test)
data.frame( R2 = R2(prediction, US_DATA_LRG_test$PM2.5),
            RMSE = RMSE(prediction, US_DATA_LRG_test$PM2.5),
            MAE = MAE(prediction, US_DATA_LRG_test$PM2.5))
```
#8 models were produced based on 8 different processes. They have similar adjusted coefficient of determination and their assumptions are valid. When testing their predictive ability, all of them have high R2 value and low Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) value. 

```{r}
#consistency of regression coefficient
valid1 = lm(PM2.5 ~ OC + SO4 + FE + NO3 + CL + SI + S + K + CA + CU + PB + P + OP + TI + SE + V + CR + SR + MN + RB, data = US_DATA_LRG)
valid2 = lm(PM2.5 ~ OC + OP + CA + CL + CR + CU + FE + PB + MN + P + K + RB + SE + SI + SR + S + TI + V + NO3 + SO4, data = US_DATA_LRG)
valid3 = lm(PM2.5 ~ OC + SO4 + FE + NO3 + CL + SI + S + K + CA + CU + PB + P + OP + TI + SE + V + CR + SR + MN + RB, data = US_DATA_LRG)
valid4 = lm(PM2.5 ~ EC + OC + OP + AL + AS + BR + CA + CL + CR + CU + FE + PB + MG + MN + NI + N2 + P + K + RB + SE + SI + NA. + SR + S + TI + V + ZN + ZR + NO3 + SO4, data = US_DATA_LRG)
valid5 = lm(PM2.5 ~ OC + SO4 + FE + NO3 + CL + SI + S + K + CA + CU + PB + P + OP + TI + SE, data = US_DATA_LRG)
valid6 = lm(PM2.5 ~ OC + OP + CA + CL + CR + CU + FE + PB + P + K + SE + SI + S + TI + V + NO3 + SO4, data = US_DATA_LRG)
valid7 = lm(PM2.5 ~ OC + SO4 + FE + NO3 + CL + SI + S + K + CA + CU + PB + P + OP + TI + SE, data = US_DATA_LRG)
valid8 = lm(PM2.5 ~ EC + OC + OP + AL + AS + BR + CA + CL + CR + CU + FE + PB + MG + MN + NI + N2 + P + K + RB + SE + SI + NA. + SR + S + TI + V + ZN + ZR + NO3 + SO4, data = US_DATA_LRG)
cbind(coef(summary(mod1))[,1], coef(summary(valid1))[,1])
cbind(coef(summary(mod2))[,1], coef(summary(valid2))[,1])
cbind(coef(summary(mod3))[,1], coef(summary(valid3))[,1])
cbind(coef(summary(mod4))[,1], coef(summary(valid4))[,1])
cbind(coef(summary(mod5))[,1], coef(summary(valid5))[,1])
cbind(coef(summary(mod6))[,1], coef(summary(valid6))[,1])
cbind(coef(summary(mod7))[,1], coef(summary(valid7))[,1])
cbind(coef(summary(mod8))[,1], coef(summary(valid8))[,1])
```
#The regression coefficients are consistency between training data and testing data in all of these models. 

```{r}
#Complexity of models
length(coef(summary(mod1))[,1])
length(coef(summary(mod2))[,1])
length(coef(summary(mod3))[,1])
length(coef(summary(mod4))[,1])
length(coef(summary(mod5))[,1])
length(coef(summary(mod6))[,1])
length(coef(summary(mod7))[,1])
length(coef(summary(mod8))[,1])
```

